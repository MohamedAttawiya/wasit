Any Lambda/service that wants to use the observability pipeline should emit structured JSON log lines (one JSON object per line) to CloudWatch Logs, and include (at minimum) the fields your transform expects: env, service, level, correlationId, msg (optionally ts). Your current Firehose setup is wired to ingest CloudWatch Logs subscription payloads, so the normal usage is: service logs → CloudWatch Log Group → subscription filter to the Firehose destination → your transform Lambda converts the CloudWatch batch into NDJSON and sets Firehose dynamic partition keys (env, service). That’s why your test worked: you manually crafted a valid CloudWatch subscription payload (messageType: DATA_MESSAGE, logEvents[].message as JSON strings), gzipped+base64’d it, and Firehose accepted it and wrote objects under env=.../service=.../date=.../.

Correlation IDs should be treated as a trace baton: generate one at the edge (API Gateway request, SQS message creation, EventBridge event emission, cron job kickoff), then pass it downstream through every hop. Practically: put it in HTTP headers (recommend x-correlation-id), in message envelopes for async (correlationId field in SQS/EventBridge payload), and in any internal RPC metadata; each service must log the same correlationId on every log line related to that workflow. Format-wise: keep it a string that’s stable, URL-safe, and easy to grep—e.g. req-<ulid> / cli-101 / order-<orderId>-<rand>; don’t embed quotes/newlines, and don’t change it mid-flight. In your working path, the “actual required format” is simply that the log line is valid JSON and includes "correlationId":"<string>", plus "env" and "service" so the transformer can both store them as columns and use them for partitioning.