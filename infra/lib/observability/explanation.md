Any Lambda/service that wants to use the observability pipeline should emit structured JSON log lines (one JSON object per line) to CloudWatch Logs, and include (at minimum) the fields your transform expects: env, service, level, correlationId, msg (optionally ts). Your current Firehose setup is wired to ingest CloudWatch Logs subscription payloads, so the normal usage is: service logs → CloudWatch Log Group → subscription filter to the Firehose destination → your transform Lambda converts the CloudWatch batch into NDJSON and sets Firehose dynamic partition keys (env, service). That’s why your test worked: you manually crafted a valid CloudWatch subscription payload (messageType: DATA_MESSAGE, logEvents[].message as JSON strings), gzipped+base64’d it, and Firehose accepted it and wrote objects under env=.../service=.../date=.../.

Correlation IDs should be treated as a trace baton: generate one at the edge (API Gateway request, SQS message creation, EventBridge event emission, cron job kickoff), then pass it downstream through every hop. Practically: put it in HTTP headers (recommend x-correlation-id), in message envelopes for async (correlationId field in SQS/EventBridge payload), and in any internal RPC metadata; each service must log the same correlationId on every log line related to that workflow. Format-wise: keep it a string that’s stable, URL-safe, and easy to grep—e.g. req-<ulid> / cli-101 / order-<orderId>-<rand>; don’t embed quotes/newlines, and don’t change it mid-flight. In your working path, the “actual required format” is simply that the log line is valid JSON and includes "correlationId":"<string>", plus "env" and "service" so the transformer can both store them as columns and use them for partitioning.

From a CDK perspective, “subscribing to observability” means: your service owns a CloudWatch Log Group, and you attach a Logs Subscription Filter that forwards everything in that log group into the central destination (wasit-dev-central-logs). Don’t hardcode the stream ARN/name inside every stack; treat it as an environment-scoped dependency resolved from SSM using your published path /${prefix}/observability/logDeliveryStreamArn (and optionally .../logDeliveryStreamName). In AWS terms, the resource you wire up is AWS::Logs::SubscriptionFilter (CDK: logs.SubscriptionFilter), and the destination is a Firehose destination (CDK: logs_destinations.KinesisFirehoseDestination, which points at the Firehose stream and uses an IAM role that allows firehose:PutRecord / firehose:PutRecordBatch). Correlation IDs then become an infrastructure contract too: at the “edge” constructs (API Gateway/Lambda, EventBridge rules, SQS queues), you standardize a single header/field name (x-correlation-id for HTTP, correlationId in event bodies) and propagate it through integrations (API Gateway mapping templates / Lambda integration, EventBridge input transformers, SQS message attributes or JSON body), so every downstream stack can stay dumb: it just logs JSON with the same correlationId, and the shared subscription filter funnels it into the same Firehose pipeline and partitions by env + service.